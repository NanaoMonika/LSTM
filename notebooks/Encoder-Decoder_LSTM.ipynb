{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addition Prediction Problem\n",
    "Known from https://arxiv.org/abs/1410.4615\n",
    "\n",
    "Below is a picture of an example of what we want to achive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Many-to-many model](./seq2seq.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "from random import seed, randint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, TimeDistributed, Dense, RepeatVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_sum_pairs(n_examples, n_numbers, largest):\n",
    "    '''Function to generate a list of random integers\n",
    "        and the sum of those integers.'''\n",
    "    X, y = [], []\n",
    "    for i in range(n_examples):\n",
    "        input_seq = [randint(1, largest) for i in range(n_numbers)]\n",
    "        output_seq = sum(input_seq)\n",
    "        X.append(input_seq)\n",
    "        y.append(output_seq)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[3, 10], [2, 5]], [13, 7])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test of above function\n",
    "seed(1)\n",
    "n_examples = 2\n",
    "n_numbers = 2\n",
    "largest = 10\n",
    "X, y = random_sum_pairs(n_examples, n_numbers, largest)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_string(X, y, n_numbers, largest):\n",
    "    '''Function to convert the output from \n",
    "    random_sum_pairs to a string representaion.'''\n",
    "    max_length = int(n_numbers * np.ceil(np.log10(largest+1)) + n_numbers - 1)\n",
    "    X_str = []\n",
    "    for i in X:\n",
    "        str_i =  '+'.join([str(n) for n in i])\n",
    "        str_i = ''.join([' ' for _ in range(max_length-len(str_i))]) + str_i\n",
    "        X_str.append(str_i)\n",
    "    max_length = int(np.ceil(np.log10(n_numbers * (largest+1))))\n",
    "    y_str = []\n",
    "    for j in y:\n",
    "        str_j = str(j)\n",
    "        str_j = ''.join([' ' for _ in range(max_length-len(str_j))]) + str_j\n",
    "        y_str.append(str_j)\n",
    "    return X_str, y_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([' 3+10', '  2+5'], ['13', ' 7'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test to_string\n",
    "X, y = to_string(X, y, n_numbers, largest)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# integer encode strings\n",
    "def integer_encode(X, y, vocab):\n",
    "    '''Function to integer encode our string \n",
    "    representation of  the input and output'''\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(vocab))\n",
    "    X_enc = []\n",
    "    for p in X:\n",
    "        integer_encoded = [char_to_int[char] for char in p]\n",
    "        X_enc.append(integer_encoded)\n",
    "    y_enc = []\n",
    "    for p in y:\n",
    "        integer_encoded = [char_to_int[char] for char in p]\n",
    "        y_enc.append(integer_encoded)\n",
    "    return X_enc, y_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11, 3, 10, 1, 0], [11, 11, 2, 10, 5]]\n",
      "[[1, 3], [11, 7]]\n"
     ]
    }
   ],
   "source": [
    "# Test integer_encode\n",
    "vocab = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', ' ']\n",
    "X, y = integer_encode(X, y, vocab)\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(X, y, max_int):\n",
    "    \"\"\"Function to one-hot encode out integer encoding\"\"\"\n",
    "    X_hot, y_hot = [], []\n",
    "    \n",
    "    for i in X:\n",
    "        seq = []\n",
    "        for j in i:\n",
    "            temp = np.zeros(max_int).astype(int)\n",
    "            temp[j] = 1\n",
    "            seq.append(temp)\n",
    "        X_hot.append(seq)\n",
    "        \n",
    "    for i in y:\n",
    "        seq = []\n",
    "        for j in i:\n",
    "            temp = np.zeros(max_int).astype(int)\n",
    "            temp[j] = 1\n",
    "            seq.append(temp)\n",
    "        y_hot.append(seq)\n",
    "    \n",
    "    return X_hot, y_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]),\n",
       "   array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "   array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]),\n",
       "   array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "   array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])],\n",
       "  [array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]),\n",
       "   array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]),\n",
       "   array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "   array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]),\n",
       "   array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0])]],\n",
       " '--------------------------------------------------------------------------------',\n",
       " [[array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "   array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])],\n",
       "  [array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]),\n",
       "   array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0])]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test  one-hot encoding\n",
    "X, y = one_hot_encode(X, y, len(vocab))\n",
    "X, '-'*80, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data(n_examples, n_numbers, largest, vocab):\n",
    "    '''Function for generating data for our model, using above\n",
    "    helper-functions.'''\n",
    "    # generate pairs\n",
    "    X, y = random_sum_pairs(n_examples, n_numbers, largest)\n",
    "    # convert to strings\n",
    "    X, y = to_string(X, y, n_numbers, largest)\n",
    "    # integer encode\n",
    "    X, y = integer_encode(X, y, vocab)\n",
    "    # one hot encode\n",
    "    X, y = one_hot_encode(X, y, len(vocab))\n",
    "    # return as NumPy arrays\n",
    "    X, y = array(X), array(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Invers transform of one-hot encoding\n",
    "def invert(seq, vocab):\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "    strings = []\n",
    "    for pattern in seq:\n",
    "        string = int_to_char[np.argmax(pattern)]\n",
    "        strings.append(string)\n",
    "    return ''.join(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of math terms\n",
    "n_terms = 3\n",
    "# largest value for any single input digit\n",
    "largest = 10\n",
    "# scope of possible symbols for each input or output time step\n",
    "vocab = [str(x) for x in range(10)] + ['+', ' ']\n",
    "# size of alphabet: (12 for 0-9, + and ' ')\n",
    "n_chars = len(alphabet)\n",
    "# length of encoded input sequence (8 for '10+10+10)\n",
    "n_in_seq_length = int(n_terms * np.ceil(np.log10(largest+1)) + n_terms - 1)\n",
    "# length of encoded output sequence (2 for '30')\n",
    "n_out_seq_length = int(np.ceil(np.log10(n_terms * (largest+1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 75)                26400     \n",
      "_________________________________________________________________\n",
      "repeat_vector_3 (RepeatVecto (None, 2, 75)             0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 2, 50)             25200     \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 2, 12)             612       \n",
      "=================================================================\n",
      "Total params: 52,212\n",
      "Trainable params: 52,212\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(75, input_shape=(n_in_seq_length, n_chars)))\n",
    "model.add(RepeatVector(n_out_seq_length))\n",
    "model.add(LSTM(50, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(n_chars, activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 59s - loss: 0.6653 - acc: 0.8106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f526cbd23c8>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "X, y = generate_data(75000, n_terms, largest, vocab)\n",
    "model.fit(X, y, epochs=1, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.111792, Accuracy: 99.500000\n"
     ]
    }
   ],
   "source": [
    "# evaluate LSTM\n",
    "X, y = generate_data(100, n_terms, largest, vocab)\n",
    "loss, acc = model.evaluate(X, y, verbose=0)\n",
    "print('Loss: %f, Accuracy: %f' % (loss, acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5+4+10 = 19 (expect 19)\n",
      "  1+6+10 = 17 (expect 17)\n",
      "  10+2+6 = 18 (expect 18)\n",
      "   4+2+3 =  9 (expect  9)\n",
      "   6+2+8 = 16 (expect 16)\n",
      " 10+2+10 = 22 (expect 22)\n",
      "   9+5+2 = 16 (expect 16)\n",
      "   2+2+1 =  6 (expect  5)\n",
      "   5+5+9 = 19 (expect 19)\n",
      "   6+4+3 = 13 (expect 13)\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "for _ in range(10):\n",
    "    # generate an input-output pair\n",
    "    X, y = generate_data(1, n_terms, largest, vocab)\n",
    "    # make prediction\n",
    "    yhat = model.predict(X, verbose=0)\n",
    "    # decode input, expected and predicted\n",
    "    in_seq = invert(X[0], vocab)\n",
    "    out_seq = invert(y[0], vocab)\n",
    "    predicted = invert(yhat[0], vocab)\n",
    "    print('%s = %s (expect %s)' % (in_seq, predicted, out_seq))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
